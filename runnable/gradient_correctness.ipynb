{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 56\n",
      "measured outcome: 0110011000 ₍₂₎\n",
      "probability of measuring the above outcome: 0.0002616637903138677054820166784700677419070212165444083615012690473173857106497774\n",
      "data type used in calculations: Float64\n",
      "note: the time (μs) taken for 'iteration i' refers to the time required for the algorithm to compute p_θ(x_i|x_1,...x_{i-1}) and ∇_θ(p_θ(x_i|x_1,...x_{i-1}))\n",
      "iteration 1: 0.31081390380859375\n",
      "iteration 2: 0.027170896530151367\n",
      "iteration 3: 0.027393102645874023\n",
      "iteration 4: 0.03413701057434082\n",
      "iteration 5: 0.02690601348876953\n",
      "iteration 6: 0.02078413963317871\n",
      "iteration 7: 0.021872997283935547\n",
      "iteration 8: 0.030344009399414062\n",
      "iteration 9: 0.02223801612854004\n",
      "iteration 10: 0.0220029354095459\n",
      "total time: 0.5436630249023438\n",
      "The ith entry in the following vector is p_θ(x_i|x_1,...x_{i-1})\n",
      "[0.3559703909266713, 0.635724784341615, 0.02725358381354659, 0.49950182735153437, 0.505037572999305, 0.6938682841194418, 0.7358149317075242, 0.338125530434357, 0.9742100869212049, 1.0]\n",
      "the product of all entries in the above vector, should match the earlier probability computed using FLOYao.bitstring_probability: 0.00026166379031386777\n",
      "The following vector is ∇_θ(log(p_θ(x))), evaluated at x = measured outcome\n",
      "[-0.11723147692605644, 0.5278587143317579, 2.1088493964730843, 0.13601704946657878, -1.3760787454354042, -0.5816743066899707, -0.2744218849549109, -0.1666610294427909, -0.24314332291634833, -0.8939293912640738, -0.29038814290154435, -0.19136976880901807, 0.024156764460646806, -0.613093257384518, -0.36879866077965484, -0.10123751788856125, -0.7053882899036116, 0.22973712556915368, -0.514062023628584, 1.0905344638530237, 0.029484916347502162, 0.2245991292958372, -0.4396276393745268, -1.0354176148474312, -0.7445394196110664, -0.47262418648201326, -0.0506807252746101, -0.017117962290154696, 1.3305797063560811, 0.15363559352580522, 0.722943342754972, 0.23591533086365088, -1.2026839189277292, -0.04296362402798328, 0.22971396786837334, 1.2450872368979011, -0.05219589829292485, -1.3111447092712178, -0.7532087668504361, 5.677904825330657, 0.5450927043621708, -0.7764104316902812, 0.5066640657175019, 0.5134972089815872, -0.3693256606919513, -0.1295104535278515, 3.115595036866898e-17, 5.6849216847563585e-19, -9.891335534969651e-17, 6.173813142209278e-17, 7.20188457154181e-17, -1.819800475220494e-16, -3.872274612683927e-17, -9.951075485030327e-17, 2.2886559402786387e-17, -8.945548515179056e-18]\n"
     ]
    }
   ],
   "source": [
    "# Constructs a quantum circuit g with parameters θ, then differentiates the recursive algorithm given in Section 5.1 of https://arxiv.org/abs/1112.2184 to obtain the gradient of p_θ(x) wrt θ, where x is a measurement of g|0>. The differentiation takes polynomial time due to memoization.\n",
    "# We then compare our results to the finite difference gradient\n",
    "\n",
    "using Yao, FLOYao\n",
    "using LinearAlgebra\n",
    "\n",
    "nq = 10 #Number of qubits\n",
    "layers = 2 #Number of brick-wall layers in the circuit\n",
    "g = chain(nq)\n",
    "for _ in 1:layers\n",
    "    for i in 1:nq-1\n",
    "        push!(g, rot(kron(nq, i => X, i+1 => X), 0.)) #Nearest-neighbor XX rotation gates\n",
    "    end\n",
    "    for i in 1:nq-1\n",
    "        push!(g, rot(kron(nq, i => X, i+1 => Y), 0.)) #Nearest-neighbor XY rotation gates\n",
    "    end\n",
    "    for i in 1:nq\n",
    "        push!(g, put(nq, i => Rz(0.))) #Single qubit Z rotation gates\n",
    "    end\n",
    "end\n",
    "\n",
    "#Set g to have random parameters\n",
    "p = rand(nparameters(g)).*2π\n",
    "dispatch!(g, p)\n",
    "nparams = nparameters(g)\n",
    "dim = 2*nq\n",
    "println(\"number of parameters: \", nparams)\n",
    "\n",
    "⊗ = kron\n",
    "\n",
    "function covariance_matrix(reg::MajoranaReg)\n",
    "    nq = nqubits(reg)\n",
    "    G = I(nq) ⊗ [0 1; -1 0]\n",
    "    return reg.state * G * reg.state'\n",
    "end\n",
    "\n",
    "function majoranaindices2kron(nq, i, j) #Returns γ_iγ_j, assuming that i≠j\n",
    "    p = []\n",
    "    c = (i % 2 == j % 2) ? 1 : -1\n",
    "    a = min(i, j)\n",
    "    b = max(i, j)\n",
    "    first = (a+1) ÷ 2 \n",
    "    last = (b+1) ÷ 2 \n",
    "    if first == last #This means i=j-1 and j is even\n",
    "        c = 1\n",
    "        push!(p, first => Z)\n",
    "    else\n",
    "        if i % 2 == 0\n",
    "            push!(p, first => X)\n",
    "            c *= 1\n",
    "        else\n",
    "            push!(p, first => Y)\n",
    "            c *= -1\n",
    "        end\n",
    "        for k in first+1:last-1\n",
    "            push!(p, k => Z)\n",
    "            c *= -1\n",
    "        end\n",
    "        if j % 2 == 0\n",
    "            push!(p, last => Y)\n",
    "        else\n",
    "            push!(p, last => X)\n",
    "        end\n",
    "    end\n",
    "    if i > j\n",
    "        c *= -1\n",
    "    end\n",
    "    return c*kron(nq, p...)\n",
    "end\n",
    "\n",
    "function majorana_commutator(nq, i, j) #Returns [γ_i,γ_j]=2γ_iγ_j, due to the anti-commutation of Majorana operators. It needs to be an 'Add' object so that the Yao.expect' function can take it in as input.\n",
    "    return Add(majoranaindices2kron(nq, i, j)) \n",
    "end\n",
    "\n",
    "function update!(reg::MajoranaReg, theta, b, temp_m, temp_grad_m, cur_m, cur_grad_m, probabilities, grad_probabilities) #Evolves all matrices and probabilities and gradients by nq steps, in-place. This method is slow but is definitely correct. I used this to check that my more optimal function was outputting the correct thing.\n",
    "    t_tot = 0\n",
    "    for i in 1:nq\n",
    "        t = time()\n",
    "        if i > 1\n",
    "            cur_m = deepcopy(temp_m)\n",
    "            cur_grad_m = deepcopy(temp_grad_m)\n",
    "            cur_prob = deepcopy(probabilities[i-1])\n",
    "            cur_grad_prob = deepcopy(grad_probabilities[i-1, :])\n",
    "            ni = b[i-1]\n",
    "            for p in 1:dim\n",
    "                for q in p+1:dim\n",
    "                    temp_grad_m[p,q] .-= (-1)^ni * ((-cur_grad_prob * cur_m[2*(i-1)-1,p] * cur_m[2*(i-1),q]) .+ (cur_prob * (cur_grad_m[2*(i-1)-1,p]*cur_m[2*(i-1),q] .+ cur_m[2*(i-1)-1,p] * cur_grad_m[2*(i-1),q]))) / (2*cur_prob^2)\n",
    "                    temp_grad_m[p,q] .+= (-1)^ni * ((-cur_grad_prob * cur_m[2*(i-1)-1,q] * cur_m[2*(i-1),p]) .+ (cur_prob * (cur_grad_m[2*(i-1)-1,q]*cur_m[2*(i-1),p] .+ cur_m[2*(i-1)-1,q] * cur_grad_m[2*(i-1),p]))) / (2*cur_prob^2)\n",
    "                    temp_grad_m[q,p] = -temp_grad_m[p,q] \n",
    "                end\n",
    "            end\n",
    "            for p in 1:dim\n",
    "                temp_grad_m[p,p] = zeros(nparams)\n",
    "            end\n",
    "            for p in 1:dim\n",
    "                for q in p+1:dim\n",
    "                    temp_m[p,q] -= (-1)^ni * (cur_m[2*(i-1)-1,p] * cur_m[2*(i-1),q]) / (2*cur_prob)\n",
    "                    temp_m[p,q] += (-1)^ni * (cur_m[2*(i-1)-1,q] * cur_m[2*(i-1),p]) / (2*cur_prob)\n",
    "                    temp_m[q,p] = -temp_m[p,q]\n",
    "                end\n",
    "            end\n",
    "            for p in 1:dim\n",
    "                temp_m[p,p] = 0.0\n",
    "            end\n",
    "            ni = b[i]\n",
    "            probabilities[i] = (1+(-1)^ni * temp_m[2*i-1, 2*i]) / 2\n",
    "            grad_probabilities[i, :] = (-1)^ni * temp_grad_m[2*i-1, 2*i] / 2\n",
    "        else\n",
    "            dispatch!(g, theta)\n",
    "            temp_m = covariance_matrix(apply(reg, g))\n",
    "            ni = b[i]\n",
    "            probabilities[i] = (1+(-1)^ni * temp_m[2*i-1, 2*i]) / 2\n",
    "            for p in 1:dim\n",
    "                for q in p+1:dim\n",
    "                    ham = majorana_commutator(nq, p, q)\n",
    "                    temp_grad_m[p,q] = expect'(ham, reg => g)[2]\n",
    "                    temp_grad_m[q,p] = -temp_grad_m[p,q]\n",
    "                end\n",
    "            end\n",
    "            for p in 1:dim\n",
    "                temp_grad_m[p,p] = zeros(nparams)\n",
    "            end\n",
    "            grad_probabilities[i, :] = (-1)^ni * temp_grad_m[2*i-1, 2*i] / 2\n",
    "        end\n",
    "        diff = time() - t\n",
    "        t_tot += diff\n",
    "        println(\"iteration $i: $diff\")\n",
    "    end\n",
    "    println(\"total time: $t_tot\")\n",
    "end \n",
    "\n",
    "function update_opt!(reg::MajoranaReg, theta, b, temp_m, temp_grad_m, probabilities, grad_probabilities) #Evolves all matrices and probabilities and gradients by nq steps, in-place and optimally\n",
    "    t_tot = 0\n",
    "    for i in 1:nq\n",
    "        t = time()\n",
    "        if i > 1\n",
    "            ni = b[i-1]\n",
    "            cur_prob = probabilities[i-1]\n",
    "            cur_grad_prob = grad_probabilities[:, i-1]\n",
    "            cur_prefactor = (-1)^ni / (2*cur_prob)\n",
    "            cur_grad_prefactor = (-1)^ni / (2*cur_prob^2)\n",
    "            for p in 2*(i-1)+1:dim\n",
    "                for q in p+1:dim\n",
    "                    temp_grad_m[:,p,q] .-= cur_grad_prefactor * ((-cur_grad_prob * temp_m[2*(i-1)-1,p] * temp_m[2*(i-1),q]) .+ (cur_prob * (temp_grad_m[:,2*(i-1)-1,p]*temp_m[2*(i-1),q] .+ temp_m[2*(i-1)-1,p] * temp_grad_m[:,2*(i-1),q])))\n",
    "                    temp_grad_m[:,p,q] .+= cur_grad_prefactor * ((-cur_grad_prob * temp_m[2*(i-1)-1,q] * temp_m[2*(i-1),p]) .+ (cur_prob * (temp_grad_m[:,2*(i-1)-1,q]*temp_m[2*(i-1),p] .+ temp_m[2*(i-1)-1,q] * temp_grad_m[:,2*(i-1),p])))\n",
    "                end\n",
    "            end\n",
    "            for p in 2*(i-1)+1:dim\n",
    "                for q in p+1:dim\n",
    "                    temp_m[p,q] -= cur_prefactor * (temp_m[2*(i-1)-1,p] * temp_m[2*(i-1),q])\n",
    "                    temp_m[p,q] += cur_prefactor * (temp_m[2*(i-1)-1,q] * temp_m[2*(i-1),p])\n",
    "                end\n",
    "            end\n",
    "            ni = b[i]\n",
    "            probabilities[i] = (1+(-1)^ni * temp_m[2*i-1, 2*i]) / 2\n",
    "            grad_probabilities[:, i] = (-1)^ni * temp_grad_m[:,2*i-1, 2*i] / 2\n",
    "        else\n",
    "            dispatch!(g, theta)\n",
    "            temp_m = covariance_matrix(apply(reg, g))\n",
    "            ni = b[i]\n",
    "            probabilities[i] = (1+(-1)^ni * temp_m[2*i-1, 2*i]) / 2\n",
    "            for p in 1:dim\n",
    "                for q in p+1:dim\n",
    "                    ham = majorana_commutator(nq, p, q)\n",
    "                    temp_grad_m[:,p,q] = expect'(ham, reg => g)[2]\n",
    "                end\n",
    "            end\n",
    "            grad_probabilities[:, i] = (-1)^ni * temp_grad_m[:,2*i-1, 2*i] / 2\n",
    "        end\n",
    "        diff = time() - t\n",
    "        t_tot += diff\n",
    "        println(\"iteration $i: $diff\")\n",
    "    end\n",
    "    println(\"total time: $t_tot\")\n",
    "end\n",
    "\n",
    "function log_grad(reg::MajoranaReg, theta, b, temp_m, temp_grad_m, cur_m, cur_grad_m, probabilities, grad_probabilities) #Returns ∇_θlog(p_θ(b)), evaluated at 'theta' (parameters of circuit) and 'b' (measurement result); 'reg' is the initial register and must be of type MajoranaReg (e.g. FLOYao.zero_state(nq))\n",
    "    nq = nqubits(reg)\n",
    "    update!(reg, theta, b, temp_m, temp_grad_m, cur_m, cur_grad_m, probabilities, grad_probabilities)\n",
    "    s = zeros(length(theta))\n",
    "    for i in 1:nq\n",
    "        s += grad_probabilities[i, :] / probabilities[i]\n",
    "    end\n",
    "    basic_prob = probabilities\n",
    "    return basic_prob, s\n",
    "end\n",
    "\n",
    "function log_grad_opt(reg::MajoranaReg, theta, b, temp_m, temp_grad_m, probabilities, grad_probabilities) #Returns ∇_θlog(p_θ(b)), evaluated at 'theta' (parameters of circuit) and 'b' (measurement result); 'reg' is the initial register and must be of type MajoranaReg (e.g. FLOYao.zero_state(nq)). This uses the optimal updating function which is more efficient but still outputs the same thing as the original update! function.\n",
    "    update_opt!(reg, theta, b, temp_m, temp_grad_m, probabilities, grad_probabilities)\n",
    "    s = zeros(length(theta))\n",
    "    for i in 1:nq\n",
    "        s += grad_probabilities[:, i] / probabilities[i]\n",
    "    end\n",
    "    optimized_prob = probabilities\n",
    "    return optimized_prob, s\n",
    "end\n",
    "\n",
    "reg = apply(FLOYao.zero_state(nq), g)\n",
    "bitstr = measure(reg, nshots = 1)[1] #Random measurement of g|0>\n",
    "println(\"measured outcome: $bitstr\")\n",
    "println(\"probability of measuring the above outcome: \", FLOYao.bitstring_probability(reg, bitstr)) #Uses FLOYao.bitstring_probability(reg, bitstr) which is known to be correct. We check this number against our algorithm output, to verify correctness.\n",
    "\n",
    "T = Float64 #Can also be BigFloat, may experiment with other data types later\n",
    "println(\"data type used in calculations: $T\") \n",
    "println(\"note: the time (μs) taken for 'iteration i' refers to the time required for the algorithm to compute p_θ(x_i|x_1,...x_{i-1}) and ∇_θ(p_θ(x_i|x_1,...x_{i-1}))\")\n",
    "\n",
    "#Initializing temporary matrices and vectors used in the unoptimal version of the algorithm.\n",
    "temp_m = Matrix{T}(undef, dim, dim)\n",
    "temp_grad_m = Matrix{Vector{T}}(undef, dim, dim)\n",
    "cur_m = Matrix{T}(undef, dim, dim)\n",
    "cur_grad_m = Matrix{Vector{T}}(undef, dim, dim)\n",
    "probabilities = Vector{T}(undef, nq)\n",
    "grad_probabilities = Matrix{T}(undef, nq, nparams)\n",
    "\n",
    "basic_prob, basic = log_grad(FLOYao.zero_state(nq), p, bitstr, temp_m, temp_grad_m, cur_m, cur_grad_m, probabilities, grad_probabilities)\n",
    "println(\"The ith entry in the following vector is p_θ(x_i|x_1,...x_{i-1})\")\n",
    "println(basic_prob)\n",
    "println(\"the product of all entries in the above vector, should match the earlier probability computed using FLOYao.bitstring_probability: \", prod(basic_prob))\n",
    "println(\"The following vector is ∇_θ(log(p_θ(x))), evaluated at x = measured outcome\")\n",
    "println(basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1: 0.03325700759887695\n",
      "iteration 2: 0.012118101119995117\n",
      "iteration 3: 0.008212804794311523\n",
      "iteration 4: 0.006367921829223633\n",
      "iteration 5: 0.008416891098022461\n",
      "iteration 6: 0.003178119659423828\n",
      "iteration 7: 0.0020661354064941406\n",
      "iteration 8: 0.0011591911315917969\n",
      "iteration 9: 0.0004830360412597656\n",
      "iteration 10: 0.00011420249938964844\n",
      "total time: 0.07537341117858887\n",
      "probabilities equal? true\n",
      "grad(log p) equal? true\n",
      "The following vector is ∇_θ(log(p_θ(x))), evaluated at x = measured outcome, as outputted by the optimized version of the algorithm.\n",
      "[-0.11723147692605644, 0.5278587143317579, 2.1088493964730843, 0.13601704946657878, -1.3760787454354042, -0.5816743066899707, -0.2744218849549109, -0.1666610294427909, -0.24314332291634833, -0.8939293912640738, -0.29038814290154435, -0.19136976880901807, 0.024156764460646806, -0.613093257384518, -0.36879866077965484, -0.10123751788856125, -0.7053882899036116, 0.22973712556915368, -0.514062023628584, 1.0905344638530237, 0.029484916347502162, 0.2245991292958372, -0.4396276393745268, -1.0354176148474312, -0.7445394196110664, -0.47262418648201326, -0.0506807252746101, -0.017117962290154696, 1.3305797063560811, 0.15363559352580522, 0.722943342754972, 0.23591533086365088, -1.2026839189277292, -0.04296362402798328, 0.22971396786837334, 1.2450872368979011, -0.05219589829292485, -1.3111447092712178, -0.7532087668504361, 5.677904825330657, 0.5450927043621708, -0.7764104316902812, 0.5066640657175019, 0.5134972089815872, -0.3693256606919513, -0.1295104535278515, 3.115595036866898e-17, 5.6849216847563585e-19, -9.891335534969651e-17, 6.173813142209278e-17, 7.20188457154181e-17, -1.819800475220494e-16, -3.872274612683927e-17, -9.951075485030327e-17, 2.2886559402786387e-17, -8.945548515179056e-18]\n"
     ]
    }
   ],
   "source": [
    "#Initializing temporary matrices and vectors for the optimized version of the algorithm.\n",
    "temp_m = Matrix{T}(undef, dim, dim)\n",
    "temp_grad_m = Array{T}(undef, nparams, dim, dim)\n",
    "probabilities = Vector{T}(undef, nq)\n",
    "grad_probabilities = Matrix{T}(undef, nparams, nq)\n",
    "\n",
    "#Calling the optimized version of the algorithm. 'optimized_prob' represents the vector with ith entry p_θ(x_i|x_1,...x_{i-1}) and 'optimized' is ∇_θ(log(p_θ(x))).\n",
    "optimized_prob, optimized = log_grad_opt(FLOYao.zero_state(nq), p, bitstr, temp_m, temp_grad_m, probabilities, grad_probabilities)\n",
    "\n",
    "#Checking that the output of the optimized algorithm still matches the output of the unoptimized algorithm.\n",
    "println(\"probabilities equal? \", basic_prob == optimized_prob)\n",
    "println(\"grad(log p) equal? \", basic == optimized)\n",
    "println(\"The following vector is ∇_θ(log(p_θ(x))), evaluated at x = measured outcome, as outputted by the optimized version of the algorithm.\")\n",
    "println(optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm output for ∇_θ(log(p_θ(x))), should be exact\n",
      "[-0.11723147692605644, 0.5278587143317579, 2.1088493964730843, 0.13601704946657878, -1.3760787454354042, -0.5816743066899707, -0.2744218849549109, -0.1666610294427909, -0.24314332291634833, -0.8939293912640738, -0.29038814290154435, -0.19136976880901807, 0.024156764460646806, -0.613093257384518, -0.36879866077965484, -0.10123751788856125, -0.7053882899036116, 0.22973712556915368, -0.514062023628584, 1.0905344638530237, 0.029484916347502162, 0.2245991292958372, -0.4396276393745268, -1.0354176148474312, -0.7445394196110664, -0.47262418648201326, -0.0506807252746101, -0.017117962290154696, 1.3305797063560811, 0.15363559352580522, 0.722943342754972, 0.23591533086365088, -1.2026839189277292, -0.04296362402798328, 0.22971396786837334, 1.2450872368979011, -0.05219589829292485, -1.3111447092712178, -0.7532087668504361, 5.677904825330657, 0.5450927043621708, -0.7764104316902812, 0.5066640657175019, 0.5134972089815872, -0.3693256606919513, -0.1295104535278515, 3.115595036866898e-17, 5.6849216847563585e-19, -9.891335534969651e-17, 6.173813142209278e-17, 7.20188457154181e-17, -1.819800475220494e-16, -3.872274612683927e-17, -9.951075485030327e-17, 2.2886559402786387e-17, -8.945548515179056e-18]\n",
      "finite difference approximation to ∇_θ(log(p_θ(x)))\n",
      "[-0.11723147434307961, 0.5278587531717598, 2.1088493891030975, 0.13601701337203498, -1.3760787305913058, -0.5816742969305806, -0.2744218840972984, -0.16666103846694721, -0.2431433048106662, -0.8939293837867979, -0.290388179120635, -0.19136978614850098, 0.024156760695563224, -0.6130932425120684, -0.3687986464597577, -0.10123750643127698, -0.7053882801067051, 0.22973712908645225, -0.514062005248013, 1.0905344351967798, 0.029484912258072038, 0.22459913914611643, -0.4396276518052147, -1.0354176123932797, -0.7445394347535452, -0.472624175630356, -0.050680722557145105, -0.017117960695495114, 1.3305796972142685, 0.15363559102679997, 0.722943342178817, 0.23591533584264687, -1.202683944294507, -0.042963600167225384, 0.22971392576899818, 1.2450872553763672, -0.05219588522034352, -1.3111446821465538, -0.7532087683004948, 5.677904794776337, 0.5450927002695611, -0.7764104066392412, 0.5066640713304101, 0.5134971979727729, -0.36932565157518027, -0.12951046270437394, 5.274360104308985e-9, -4.687525524814266e-9, 7.138437207716225e-9, -7.575533582488648e-10, -6.863832091886913e-9, -1.187292701152327e-8, 1.7571597999467303e-8, -1.0140839424367574e-8, -2.001671362367593e-8, 5.551115123125782e-9]\n",
      "l2 distance between algorithm output and finite difference approximation: \n",
      "1.2295261982555076e-7\n"
     ]
    }
   ],
   "source": [
    "#Comparison with finite difference method\n",
    "using LinearAlgebra\n",
    "\n",
    "function prob(theta, x) #Outputs p_θ(x), the probability of measuring an outcome of 'x' for the state g|0> where the parameters of g are set to 'theta'\n",
    "    circuit = dispatch(g, theta)\n",
    "    r = apply(FLOYao.zero_state(nq), circuit)\n",
    "    return FLOYao.bitstring_probability(r, x)\n",
    "end\n",
    "\n",
    "eps_default = 1e-8\n",
    "function fe_grad_prob(theta, x, eps = eps_default) #Computes the finite-difference approximation for ∇_θ(log(p_θ(x))), evaluated at 'x'. I mainly used this to verify the correctness of the algorithm\n",
    "    temp_params = copy(theta)\n",
    "    fe_grad = Vector{Float64}(undef, length(theta))\n",
    "    for i in 1:nparameters(g)\n",
    "        temp_params[i] += eps\n",
    "        plus = log(prob(temp_params, x))\n",
    "        temp_params[i] -= 2*eps\n",
    "        minus = log(prob(temp_params, x))\n",
    "        fe_grad[i] = (plus - minus) / (2*eps)\n",
    "        temp_params[i] += eps #Resetting temp_params[i] back to original value\n",
    "    end\n",
    "    fe_grad\n",
    "end\n",
    "\n",
    "println(\"algorithm output for ∇_θ(log(p_θ(x))), should be exact\")\n",
    "println(basic)\n",
    "fe = fe_grad_prob(p, bitstr)\n",
    "println(\"finite difference approximation to ∇_θ(log(p_θ(x)))\")\n",
    "println(fe)\n",
    "println(\"l2 distance between algorithm output and finite difference approximation: \")\n",
    "println(norm(basic - fe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.1",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
