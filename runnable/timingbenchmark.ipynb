{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in generator: 194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "194-element Vector{Float64}:\n",
       " -0.0007070949380638301\n",
       "  0.00040243453529448427\n",
       " -0.0002098213072177955\n",
       " -2.8532238766124325e-5\n",
       "  0.00020457259516333388\n",
       "  0.00017983441619713248\n",
       " -4.983505924153254e-5\n",
       "  0.0012679993233929599\n",
       "  0.0005826959176924992\n",
       " -8.81157108852577e-5\n",
       "  ⋮\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       "  0.0\n",
       " -6.97747113429535e-21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Constructs a quantum circuit g with parameters θ, then differentiates the recursive algorithm given in Section 5.1 of https://arxiv.org/abs/1112.2184 to obtain the gradient of p_θ(x) wrt θ, where x is a measurement of g|0>. The differentiation takes polynomial time due to memoization.\n",
    "# We then compare our results to the finite difference gradient\n",
    "using Yao, FLOYao\n",
    "using LinearAlgebra\n",
    "using BenchmarkTools\n",
    "\n",
    "function create_circuit(nq::Int)\n",
    "    layers = 2 #Number of brick-wall layers in the circuit\n",
    "    g = chain(nq)\n",
    "    for _ in 1:layers\n",
    "        for i in 1:2:nq-1\n",
    "            push!(g, rot(kron(nq, i => X, i+1 => X), 0.)) #Nearest-neighbor XX rotation gates\n",
    "        end\n",
    "        for i in 2:2:nq-1\n",
    "            push!(g, rot(kron(nq, i => X, i+1 => Y), 0.)) #Nearest-neighbor XY rotation gates\n",
    "        end\n",
    "        for i in 1:nq\n",
    "            push!(g, put(nq, i => Rz(0.))) #Single qubit Z rotation gates\n",
    "        end\n",
    "    end\n",
    "    return g\n",
    "end\n",
    "\n",
    "⊗ = kron\n",
    "\n",
    "function covariance_matrix(reg::MajoranaReg)\n",
    "    nq = nqubits(reg)\n",
    "    G = I(nq) ⊗ [0 1; -1 0]\n",
    "    return reg.state * G * reg.state'\n",
    "end\n",
    "\n",
    "function majoranaindices2kron(nq, i, j) #Returns (im/2)γ_iγ_j, assuming that i≠j\n",
    "    p = []\n",
    "    c = (i % 2 == j % 2) ? 1 : -1\n",
    "    a = min(i, j)\n",
    "    b = max(i, j)\n",
    "    first = (a+1) ÷ 2 \n",
    "    last = (b+1) ÷ 2 \n",
    "    if first == last #This means i=j-1 and j is even\n",
    "        c = 1\n",
    "        push!(p, first => Z)\n",
    "    else\n",
    "        if a % 2 == 0\n",
    "            push!(p, first => X)\n",
    "            c *= 1\n",
    "        else\n",
    "            push!(p, first => Y)\n",
    "            c *= -1\n",
    "        end\n",
    "        for k in first+1:last-1\n",
    "            push!(p, k => Z)\n",
    "            c *= -1\n",
    "        end\n",
    "        if b % 2 == 0\n",
    "            push!(p, last => Y)\n",
    "        else\n",
    "            push!(p, last => X)\n",
    "        end\n",
    "    end\n",
    "    if i > j\n",
    "        c *= -1\n",
    "    end\n",
    "    return c*kron(nq, p...)\n",
    "end\n",
    "\n",
    "function majorana_commutator(nq, i, j) #Returns [γ_i,γ_j]=2γ_iγ_j, due to the anti-commutation of Majorana operators. It needs to be an 'Add' object so that the Yao.expect' function can take it in as input.\n",
    "    return Add(majoranaindices2kron(nq, i, j)) \n",
    "end\n",
    "\n",
    "function update_opt!(reg::MajoranaReg, theta, b, temp_m, temp_grad_m, probabilities, grad_probabilities) #Evolves all matrices and probabilities and gradients by nq steps, in-place and optimally\n",
    "    dim = 2*nq\n",
    "    for i in 1:nq\n",
    "        t = time()\n",
    "        if i > 1\n",
    "            ni = b[i-1]\n",
    "            cur_prob = probabilities[i-1]\n",
    "            cur_grad_prob = grad_probabilities[:, i-1]\n",
    "            cur_prefactor = (-1)^ni / (2*cur_prob)\n",
    "            cur_grad_prefactor = (-1)^ni / (2*cur_prob^2)\n",
    "            @inbounds for p in 2*(i-1)+1:dim\n",
    "                for q in p+1:dim\n",
    "                    for s in size(temp_grad_m, 1)\n",
    "                        temp_grad_m[s,p,q] -= cur_grad_prefactor * ((-cur_grad_prob[s] * temp_m[2*(i-1)-1,p] * temp_m[2*(i-1),q]) + (cur_prob * (temp_grad_m[s, 2*(i-1)-1,p] * temp_m[2*(i-1),q] + temp_m[2*(i-1)-1,p] * temp_grad_m[s,2*(i-1),q])))\n",
    "                        temp_grad_m[s,p,q] += cur_grad_prefactor * ((-cur_grad_prob[s] * temp_m[2*(i-1)-1,q] * temp_m[2*(i-1),p]) + (cur_prob * (temp_grad_m[s, 2*(i-1)-1,q] * temp_m[2*(i-1),p] + temp_m[2*(i-1)-1,q] * temp_grad_m[s,2*(i-1),p])))\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            for p in 2*(i-1)+1:dim\n",
    "                for q in p+1:dim\n",
    "                    temp_m[p,q] -= cur_prefactor * (temp_m[2*(i-1)-1,p] * temp_m[2*(i-1),q])\n",
    "                    temp_m[p,q] += cur_prefactor * (temp_m[2*(i-1)-1,q] * temp_m[2*(i-1),p])\n",
    "                end\n",
    "            end\n",
    "            ni = b[i]\n",
    "            probabilities[i] = (1+(-1)^ni * temp_m[2*i-1, 2*i]) / 2\n",
    "            grad_probabilities[:, i] = (-1)^ni * temp_grad_m[:,2*i-1, 2*i] / 2\n",
    "        else\n",
    "            dispatch!(g, theta)\n",
    "            temp_m = covariance_matrix(apply(reg, g))\n",
    "            ni = b[i]\n",
    "            probabilities[i] = (1+(-1)^ni * temp_m[2*i-1, 2*i]) / 2\n",
    "            for p in 1:dim\n",
    "                for q in p+1:dim\n",
    "                    ham = majorana_commutator(nq, p, q)\n",
    "                    temp_grad_m[:,p,q] = expect'(ham, reg => g)[2]\n",
    "                end\n",
    "            end\n",
    "            grad_probabilities[:, i] = (-1)^ni * temp_grad_m[:,2*i-1, 2*i] / 2\n",
    "        end\n",
    "        # diff = (time() - t)\n",
    "        # t_tot += diff\n",
    "        # println(\"iteration $i: $diff\")\n",
    "    end\n",
    "    # println(\"total time: $t_tot\")\n",
    "end\n",
    "\n",
    "function log_grad_opt(reg::MajoranaReg, theta, b, temp_m, temp_grad_m, probabilities, grad_probabilities) #Returns ∇_θlog(p_θ(b)), evaluated at 'theta' (parameters of circuit) and 'b' (measurement result); 'reg' is the initial register and must be of type MajoranaReg (e.g. FLOYao.zero_state(nq)).\n",
    "    update_opt!(reg, theta, b, temp_m, temp_grad_m, probabilities, grad_probabilities)\n",
    "    s = zeros(length(theta))\n",
    "    for i in 1:nq\n",
    "        s += grad_probabilities[:, i] / probabilities[i]\n",
    "    end\n",
    "    return probabilities, s\n",
    "end\n",
    "\n",
    "using Yao.BitBasis\n",
    "using Flux\n",
    "\n",
    "function postprocess(g_output::Vector) #turns output of measure  into an Int vector\n",
    "    result = []\n",
    "    for i in 1:nq\n",
    "        push!(result, g_output[1][end - i + 1])\n",
    "    end\n",
    "    Int.(result)\n",
    "end\n",
    "function d_postprocess(measurement::Vector, nbatch = batchsize)\n",
    "    aa = breflect.(measurement)\n",
    "    ret = Matrix(undef, nq, nbatch)\n",
    "    for i in 1:nbatch\n",
    "        ret[:,i] = [aa[i]...]\n",
    "    end\n",
    "    return ret\n",
    "end\n",
    "\n",
    "function g_loss(reg, g, theta, nbatch)\n",
    "    nq = nqubits(g)\n",
    "    dispatch!(g, theta)\n",
    "    measurements = measure(reg, nshots = nbatch)\n",
    "    discriminator_output = log.(d(d_postprocess(measurements, nbatch)))\n",
    "    probs = Vector{Float64}(undef, nbatch)\n",
    "    for i in 1:nbatch\n",
    "        probs[i] = FLOYao.bitstring_probability(reg, measurements[i])    \n",
    "    end\n",
    "    return -discriminator_output * probs |> first\n",
    "end\n",
    "\n",
    "function reinforce_grad_loss(reg, theta, nbatch)\n",
    "    dispatch!(g, theta)\n",
    "    T = Float64\n",
    "    sampled = Dict{BitStr{nq, BigInt}, Vector{T}}()\n",
    "    measurements = measure(apply(reg, g), nshots = nbatch)\n",
    "    discriminator_output = log.(d(d_postprocess(measurements, nbatch)))\n",
    "    #Initializing temporary matrices and vectors for the optimized version of the algorithm. Note: Do NOT need to reset these temporary matrices at the end of each iteration of the for loop.\n",
    "    dim = 2*nq\n",
    "    nparams = nparameters(g)\n",
    "    temp_m = Matrix{T}(undef, dim, dim)\n",
    "    temp_grad_m = Array{T}(undef, nparams, dim, dim)\n",
    "    probabilities = Vector{T}(undef, nq)\n",
    "    grad_probabilities = Matrix{T}(undef, nparams, nq)\n",
    "    grad_p = Matrix{T}(undef, nparams, nbatch)\n",
    "    # println(measurements)\n",
    "    for i in 1:nbatch\n",
    "        cur_bitstr = measurements[i]\n",
    "        if haskey(sampled, cur_bitstr)\n",
    "            grad_p[:,i] = sampled[cur_bitstr]\n",
    "        else\n",
    "            _, log_grad = log_grad_opt(FLOYao.zero_state(nq), theta, cur_bitstr, temp_m, temp_grad_m, probabilities, grad_probabilities)\n",
    "            grad_p[:,i] = log_grad\n",
    "            sampled[cur_bitstr] = log_grad\n",
    "        end\n",
    "    end\n",
    "    # println(sampled)\n",
    "    return vec(mean(discriminator_output.*grad_p, dims = 2))\n",
    "end\n",
    "mean(x; dims) = sum(x; dims)/length(x)\n",
    "\n",
    "nq = 64 #Number of qubits\n",
    "d = Chain(Dense(nq, 10, relu), Dense(10, 1, sigmoid))\n",
    "nparams = sum(length, Flux.params(d))\n",
    "g = create_circuit(nq)\n",
    "println(\"Number of parameters in generator: \", nparameters(g))\n",
    "p = rand(nparameters(g)).*2π\n",
    "reg = FLOYao.zero_state(nq)\n",
    "nshots = 100\n",
    "reinforce_grad_loss(reg, p, nshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function parametershift_grad(reg, g, theta, nbatch) #Shift parameters in-place\n",
    "#     l = nparameters(g)\n",
    "#     temp_params = theta\n",
    "#     temp_params[1] += π/2\n",
    "#     grad = zeros(l)\n",
    "#     for i in 1:l\n",
    "#         plus = 0\n",
    "#         minus = 0\n",
    "#         dispatch!(g, temp_params)\n",
    "#         plus = g_loss(reg, g, theta, nbatch)\n",
    "#         temp_params[i] -= π\n",
    "#         dispatch!(g, temp_params)\n",
    "#         minus = g_loss(reg, g, theta, nbatch)\n",
    "#         grad[i] = (plus - minus) / 2\n",
    "#         if i < l\n",
    "#             temp_params[i] += π/2\n",
    "#             temp_params[i+1] += π/2\n",
    "#         end\n",
    "#     end\n",
    "#     temp_params[l] += π/2\n",
    "#     dispatch!(g, temp_params)\n",
    "#     return grad\n",
    "# end\n",
    "\n",
    "# reg = FLOYao.zero_state(nq)\n",
    "# g = create_circuit(nq)\n",
    "# p = rand(nparameters(g)).*2π\n",
    "# @benchmark parametershift_grad(reg, g, p, nshots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
