{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Yao\n",
    "using FLOYao\n",
    "using Statistics\n",
    "\n",
    "N = 2\n",
    "\n",
    "g = chain(N)\n",
    "push!(g, rot(kron(N, 1 => X, 2 => X), 0.)) #Rxx on two qubits\n",
    "dispatch!(g, rand(nparameters(g)).*2π)\n",
    "theta = first(parameters(g))\n",
    "println(\"true gradient: \", sin(theta)/2)\n",
    "\n",
    "function loss(theta = theta)\n",
    "    sin(theta/2)^2\n",
    "end\n",
    "\n",
    "ratio = 0\n",
    "function pprior() #For each square, probability ratio that it's white, where ratio ~ N(mean(data), std(data)) /  N; maybe we can vary pprior later?\n",
    "    a = rand(N) .< ratio\n",
    "    return FLOYao.product_state(Int.(a)) #Returns MajoranaReg; Prepares it to be sent through the generator \n",
    "end\n",
    "\n",
    "function postprocess(g_output::Vector) #turns the output of reg |> g |> measure into an Int vector\n",
    "    result = []\n",
    "    for i in 1:N \n",
    "        push!(result, g_output[1][end - i + 1])\n",
    "    end\n",
    "    Int.(result)\n",
    "end\n",
    "\n",
    "samplemean_batch = 5000\n",
    "function run_g(nbatch = samplemean_batch)\n",
    "    samples = []\n",
    "    for i in 1:nbatch\n",
    "        z = pprior() #MajoranaReg object\n",
    "        result = z |> g |> measure |> postprocess\n",
    "        if i == 1\n",
    "            samples = result\n",
    "        else\n",
    "            samples = hcat(samples, result) #is this operation slow; on another note there has to be a better way to write this function right\n",
    "        end\n",
    "    end\n",
    "    samples\n",
    "end\n",
    "#outputs an N * #samples matrix\n",
    "\n",
    "function run_d_fake(samples)\n",
    "    # if size(samples)[1] != N || typeof(samples) != Matrix{Int64} #Require samples to be an N x #samples matrix\n",
    "    #     println(\"Improper formatting of samples\")\n",
    "    #     return\n",
    "    # end\n",
    "    # samples |> d\n",
    "    mean(samples, dims = 1)\n",
    "end\n",
    "\n",
    "function gLoss(nbatch = samplemean_batch)\n",
    "    #-mean(log.(run_d_fake(run_g(nbatch))))\n",
    "    mean(run_d_fake(run_g(nbatch)))\n",
    "end\n",
    "\n",
    "eps = 1e-5\n",
    "function finitediff_grad(g = g, eps = eps) #Computes forward finite differences\n",
    "    original = gLoss()\n",
    "    println(\"original loss: $original\")\n",
    "    a = loss(theta)\n",
    "    println(\"original true loss: $a\")\n",
    "    temp_params = parameters(g)\n",
    "    grad = zeros(nparameters(g))\n",
    "    temp = 0\n",
    "    for i in 1:nparameters(g)\n",
    "        plus = 0\n",
    "        temp = parameters(g)[i]\n",
    "        temp_params[i] = temp + eps\n",
    "        dispatch!(g, temp_params)\n",
    "        plus = gLoss()\n",
    "        println(\"plus: $plus\")\n",
    "        b = loss(theta + eps)\n",
    "        println(\"plus true loss: $b\")\n",
    "        grad[i] = (plus - original) / eps #(L(θ+ε_i) - L(θ))/ε; L is computed by sample means\n",
    "        println(\"true finitediff: \", (b-a) / eps)\n",
    "        println(plus - original)\n",
    "        println(b - a)\n",
    "        temp_params[i] = temp\n",
    "        dispatch!(g, temp_params)\n",
    "    end\n",
    "    grad\n",
    "end\n",
    "\n",
    "function parametershift_grad()\n",
    "    temp_params = parameters(g)\n",
    "    grad = zeros(nparameters(g))\n",
    "    for i in 1:nparameters(g)\n",
    "        plus = 0\n",
    "        minus = 0\n",
    "        temp = parameters(g)[i]\n",
    "        temp_params[i] = temp + π/2\n",
    "        dispatch!(g, temp_params)\n",
    "        plus = gLoss()\n",
    "        temp_params[i] = temp - π/2\n",
    "        dispatch!(g, temp_params)\n",
    "        minus = gLoss()\n",
    "        grad[i] = (plus - minus) / 2\n",
    "        temp_params[i] = temp\n",
    "        dispatch!(g, temp_params)\n",
    "    end\n",
    "    grad\n",
    "end\n",
    "\n",
    "finitediff_grad() |> println\n",
    "parametershift_grad() |> println\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
